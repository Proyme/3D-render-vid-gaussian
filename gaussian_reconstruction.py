"""
Reconstruction 3D avec Gaussian Splatting
Optimis√© pour RTX 5090 - GPU 100%
Version Ultra-Rapide: 1-2 minutes
"""

import subprocess
import cv2
import numpy as np
from pathlib import Path
import uuid
import torch
import json
import shutil

def reconstruct_3d_gaussian(video_path: str, output_glb: str):
    """
    Reconstruction 3D ultra-rapide avec Gaussian Splatting
    Optimis√© RTX 5090 - 1-2 minutes
    """
    print("üöÄ Reconstruction 3D avec Gaussian Splatting (RTX 5090)")
    
    # Cr√©er workspace (Gaussian Splatting attend un dossier "images")
    video_name = Path(video_path).stem
    workspace = Path("gaussian_workspace") / video_name
    images_dir = workspace / "images"  # Gaussian Splatting cherche "images/"
    output_dir = workspace / "output"
    
    workspace.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(exist_ok=True)
    output_dir.mkdir(exist_ok=True)
    
    try:
        # √âtape 1 : Extraction et segmentation des frames (GPU)
        print("  1/4 Extraction des frames + Segmentation GPU...")
        extract_frames_gpu(video_path, images_dir, max_frames=50)
        
        num_frames = len(list(images_dir.glob("*.jpg")))
        print(f"  ‚úì {num_frames} frames extraites et segment√©es")
        
        # √âtape 2 : COLMAP rapide pour poses de cam√©ra (minimal)
        print("  2/4 Estimation des poses cam√©ra (COLMAP minimal)...")
        success = run_colmap_minimal(images_dir, workspace)
        
        if not success:
            print("  ‚ùå √âchec estimation poses")
            return False
        
        # √âtape 3 : Gaussian Splatting (GPU 100%)
        print("  3/4 Gaussian Splatting (GPU RTX 5090 - 100%)...")
        success = run_gaussian_splatting(workspace, output_dir)
        
        if not success:
            print("  ‚ùå √âchec Gaussian Splatting")
            return False
        
        # √âtape 4 : Copier le PLY Gaussian (pas de conversion)
        print("  4/4 Export PLY Gaussian...")
        ply_source = output_dir / "point_cloud" / "iteration_3000" / "point_cloud.ply"
        
        if not ply_source.exists():
            print(f"  ‚ùå Fichier PLY non trouv√©: {ply_source}")
            return False
        
        # Copier directement le PLY (format natif Gaussian Splatting)
        shutil.copy(str(ply_source), output_glb)
        print(f"  ‚úÖ PLY export√©: {output_glb}")
        
        print("‚úÖ Reconstruction termin√©e !")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return False

def extract_frames_gpu(video_path: str, output_dir: Path, max_frames: int = 50):
    """
    Extraction + Segmentation GPU avec PyTorch + rembg
    Optimis√© RTX 5090
    """
    from PIL import Image
    from rembg import remove, new_session
    
    # Session GPU avec PyTorch
    print("    üî• Initialisation GPU RTX 5090...")
    if torch.cuda.is_available():
        device = torch.cuda.get_device_name(0)
        print(f"    ‚úÖ GPU d√©tect√©: {device}")
        session = new_session("u2net", providers=['CUDAExecutionProvider'])
    else:
        print("    ‚ö†Ô∏è  GPU non disponible, utilisation CPU")
        session = new_session("u2net")
    
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # S√©lection intelligente des frames
    frame_interval = max(1, total_frames // (max_frames * 3))
    
    candidates = []
    frame_count = 0
    
    print("    üîÑ Analyse des frames...")
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        if frame_count % frame_interval == 0:
            # Calculer nettet√©
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            candidates.append({
                'frame': frame.copy(),
                'sharpness': sharpness,
                'index': frame_count
            })
        
        frame_count += 1
    
    cap.release()
    
    # S√©lectionner meilleures frames
    candidates.sort(key=lambda x: x['sharpness'], reverse=True)
    best_frames = candidates[:max_frames]
    best_frames.sort(key=lambda x: x['index'])
    
    print(f"    ‚úì {len(best_frames)} meilleures frames s√©lectionn√©es")
    print("    üî• Segmentation GPU en cours...")
    
    # Segmentation GPU (batch processing pour plus de vitesse)
    for i, candidate in enumerate(best_frames):
        frame = candidate['frame']
        
        # BGR ‚Üí RGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(frame_rgb)
        
        # Segmentation GPU
        output = remove(
            pil_image,
            session=session,
            alpha_matting=True,
            alpha_matting_foreground_threshold=270,
            alpha_matting_background_threshold=5,
            alpha_matting_erode_size=15
        )
        
        # Nettoyer le masque
        if output.mode == 'RGBA':
            alpha = output.split()[3]
            alpha_np = np.array(alpha)
            
            _, alpha_thresh = cv2.threshold(alpha_np, 200, 255, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(alpha_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                mask_clean = np.zeros_like(alpha_np)
                cv2.drawContours(mask_clean, [largest_contour], -1, 255, -1)
                
                kernel = np.ones((3,3), np.uint8)
                mask_clean = cv2.dilate(mask_clean, kernel, iterations=1)
                
                output.putalpha(Image.fromarray(mask_clean))
        
        # Fond blanc
        if output.mode == 'RGBA':
            background = Image.new('RGB', output.size, (255, 255, 255))
            background.paste(output, mask=output.split()[3])
            output = background
        
        # Sauvegarder
        output_path = output_dir / f"{i:04d}.jpg"
        output.save(output_path, 'JPEG', quality=95)
        
        if (i + 1) % 10 == 0:
            print(f"    ‚úì {i + 1}/{len(best_frames)} frames trait√©es (GPU)")
    
    print(f"    ‚úÖ {len(best_frames)} frames segment√©es (GPU)")

def run_colmap_minimal(images_dir: Path, workspace: Path):
    """
    COLMAP minimal juste pour les poses cam√©ra
    Version rapide CPU (suffisant pour poses)
    """
    database_path = workspace / "database.db"
    sparse_dir = workspace / "sparse"
    sparse_dir.mkdir(exist_ok=True)
    
    colmap_exe = "colmap"
    
    try:
        # Feature extraction (CPU rapide)
        print("    üîç Feature extraction...")
        result = subprocess.run([
            colmap_exe, "feature_extractor",
            "--database_path", str(database_path),
            "--image_path", str(images_dir),
            "--ImageReader.single_camera", "1",
            "--ImageReader.camera_model", "PINHOLE",
            "--SiftExtraction.use_gpu", "0"
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"    ‚ùå Feature extraction failed: {result.stderr}")
            return False
        
        # Feature matching (CPU rapide)
        print("    üîó Feature matching...")
        result = subprocess.run([
            colmap_exe, "exhaustive_matcher",
            "--database_path", str(database_path),
            "--SiftMatching.use_gpu", "0"
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"    ‚ùå Feature matching failed: {result.stderr}")
            return False
        
        # Mapper (reconstruction minimale)
        print("    üó∫Ô∏è  Reconstruction...")
        result = subprocess.run([
            colmap_exe, "mapper",
            "--database_path", str(database_path),
            "--image_path", str(images_dir),
            "--output_path", str(sparse_dir)
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"    ‚ùå Mapper failed: {result.stderr}")
            return False
        
        # V√©rifier
        model_dir = sparse_dir / "0"
        if not model_dir.exists():
            print("    ‚ùå Aucun mod√®le cr√©√© par COLMAP")
            return False
        
        # Convertir en format texte pour Gaussian Splatting
        print("    üìÑ Conversion format...")
        sparse_txt_dir = workspace / "sparse_txt"
        sparse_txt_dir.mkdir(exist_ok=True)
        
        result = subprocess.run([
            colmap_exe, "model_converter",
            "--input_path", str(model_dir),
            "--output_path", str(sparse_txt_dir),
            "--output_type", "TXT"
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"    ‚ùå Model converter failed: {result.stderr}")
            return False
        
        print("    ‚úÖ COLMAP termin√©")
        return True
        
    except Exception as e:
        print(f"    ‚ùå Erreur COLMAP: {e}")
        return False

def run_gaussian_splatting(workspace: Path, output_dir: Path):
    """
    Gaussian Splatting - GPU 100%
    Ultra rapide sur RTX 5090
    """
    try:
        # V√©rifier que gaussian-splatting est install√©
        gs_path = Path("/workspace/gaussian-splatting")
        
        if not gs_path.exists():
            print("    ‚ö†Ô∏è  Gaussian Splatting non install√©, installation...")
            subprocess.run([
                "git", "clone", "--recursive",
                "https://github.com/graphdeco-inria/gaussian-splatting",
                "/workspace/gaussian-splatting"
            ], check=True)
            
            # Installer d√©pendances
            subprocess.run([
                "pip3", "install",
                "-r", str(gs_path / "requirements.txt")
            ], check=True)
            
            # Compiler CUDA kernels
            subprocess.run([
                "pip3", "install",
                str(gs_path / "submodules/diff-gaussian-rasterization"),
                str(gs_path / "submodules/simple-knn")
            ], check=True)
        
        # Lancer training (GPU 100%)
        print("    üî• Training Gaussian Splatting (GPU 100%)...")
        subprocess.run([
            "python3", str(gs_path / "train.py"),
            "-s", str(workspace),
            "-m", str(output_dir),
            "--iterations", "7000",
            "--test_iterations", "-1",
            "--save_iterations", "7000"
        ], check=True)
        
        return True
        
    except Exception as e:
        print(f"    ‚ùå Erreur Gaussian Splatting: {e}")
        return False

def convert_gaussian_to_glb(ply_path: str, glb_path: str):
    """
    Convertit Gaussian Splatting PLY en GLB - Version simplifi√©e avec Ball Pivoting
    """
    import trimesh
    from plyfile import PlyData
    import open3d as o3d
    
    try:
        print("    üîÑ Conversion PLY ‚Üí GLB...")
        
        # Charger le PLY Gaussian
        plydata = PlyData.read(ply_path)
        vertex_data = plydata['vertex'].data
        
        # Extraire positions
        positions = np.vstack([vertex_data['x'], vertex_data['y'], vertex_data['z']]).T
        
        # Extraire couleurs
        if 'red' in vertex_data.dtype.names:
            colors = np.vstack([
                vertex_data['red'],
                vertex_data['green'],
                vertex_data['blue']
            ]).T
            if colors.max() > 1.0:
                colors = colors / 255.0
        else:
            colors = np.ones_like(positions) * 0.7
        
        print(f"    ‚úì {len(positions)} points charg√©s")
        
        # Convertir en Open3D
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(positions)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # Sous-√©chantillonner pour r√©duire le bruit
        print("    üîÑ Sous-√©chantillonnage...")
        pcd = pcd.voxel_down_sample(voxel_size=0.01)
        
        # Estimer les normales
        print("    üîÑ Estimation des normales...")
        pcd.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.02, max_nn=30)
        )
        pcd.orient_normals_consistent_tangent_plane(30)
        
        # Poisson reconstruction (meilleur pour Gaussian Splatting)
        print("    üîÑ Reconstruction Poisson optimis√©e...")
        mesh_o3d, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
            pcd, depth=9, width=0, scale=1.1, linear_fit=False
        )
        
        # Nettoyer agressivement les artefacts (densit√© faible = bruit)
        print("    üßπ Suppression des artefacts...")
        vertices_to_remove = densities < np.quantile(densities, 0.1)
        mesh_o3d.remove_vertices_by_mask(vertices_to_remove)
        
        print(f"    ‚úì {len(mesh_o3d.triangles)} triangles cr√©√©s")
        
        # Nettoyer
        print("    üßπ Nettoyage...")
        mesh_o3d.remove_degenerate_triangles()
        mesh_o3d.remove_duplicated_triangles()
        mesh_o3d.remove_duplicated_vertices()
        mesh_o3d.remove_non_manifold_edges()
        
        # Transf√©rer les couleurs
        print("    üé® Application des couleurs...")
        positions_pcd = np.asarray(pcd.points)
        colors_pcd = np.asarray(pcd.colors)
        mesh_vertices = np.asarray(mesh_o3d.vertices)
        
        from scipy.spatial import KDTree
        tree = KDTree(positions_pcd)
        distances, indices = tree.query(mesh_vertices, k=1)
        mesh_colors = colors_pcd[indices]
        
        mesh_o3d.vertex_colors = o3d.utility.Vector3dVector(mesh_colors)
        mesh_o3d.compute_vertex_normals()
        
        # Simplifier si trop de triangles
        if len(mesh_o3d.triangles) > 100000:
            print("    üîÑ Simplification...")
            mesh_o3d = mesh_o3d.simplify_quadric_decimation(target_number_of_triangles=100000)
        
        # Centrer et normaliser
        center = mesh_o3d.get_center()
        mesh_o3d.translate(-center)
        max_bound = np.max(mesh_o3d.get_max_bound() - mesh_o3d.get_min_bound())
        if max_bound > 0:
            mesh_o3d.scale(1.0 / max_bound, center=mesh_o3d.get_center())
        
        # Exporter
        print("    üíæ Export GLB...")
        temp_ply = str(Path(ply_path).parent / "temp_mesh.ply")
        o3d.io.write_triangle_mesh(temp_ply, mesh_o3d, write_vertex_colors=True)
        
        # Charger avec trimesh
        mesh = trimesh.load(temp_ply)
        
        # V√©rifier que les couleurs sont pr√©sentes
        if not hasattr(mesh.visual, 'vertex_colors') or mesh.visual.vertex_colors is None:
            print("    ‚ö†Ô∏è  Couleurs manquantes, application d'une couleur par d√©faut...")
            mesh.visual.vertex_colors = np.ones((len(mesh.vertices), 4)) * [200, 200, 200, 255]
        
        # S'assurer que le mesh a des faces (pas juste wireframe)
        if len(mesh.faces) == 0:
            print("    ‚ùå Aucune face d√©tect√©e!")
            return False
        
        print(f"    ‚úì {len(mesh.vertices)} vertices, {len(mesh.faces)} faces")
        
        # Exporter en GLB avec les bonnes options
        mesh.export(
            glb_path, 
            file_type='glb',
            include_normals=True
        )
        
        Path(temp_ply).unlink()
        
        print(f"    ‚úÖ GLB export√©: {glb_path}")
        return True
        
    except Exception as e:
        print(f"    ‚ùå Erreur conversion: {e}")
        import traceback
        traceback.print_exc()
        return False

#!/bin/bash

echo "ðŸš€ DÃ©marrage Backend 3D - TripoSR"
echo "=================================="

# VÃ©rifier GPU
echo "ðŸ“Š VÃ©rification GPU..."
nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv,noheader

echo ""
echo "âœ… GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader)"
echo "âœ… CUDA: $(nvcc --version | grep release | awk '{print $5}' | sed 's/,//')"
echo "âœ… Compute: $(nvidia-smi --query-gpu=compute_cap --format=csv,noheader)"
echo "âš¡ Performance estimÃ©e: 30-60 secondes/gÃ©nÃ©ration"

# CrÃ©er les dossiers
mkdir -p uploads outputs gaussian_workspace

# Variables d'environnement
export QT_QPA_PLATFORM=offscreen
export CUDA_VISIBLE_DEVICES=0

# VÃ©rifier PyTorch + CUDA
echo ""
python3 << 'EOF'
import torch
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f"âœ… GPU: {gpu_name}")
    print(f"âœ… CUDA: {torch.version.cuda}")
    print(f"âœ… Compute: {torch.cuda.get_device_capability(0)}")
    
    if "4090" in gpu_name:
        print("âš¡ Performance estimÃ©e: 2-3 minutes/gÃ©nÃ©ration")
    elif "3090" in gpu_name:
        print("âš¡ Performance estimÃ©e: 3-4 minutes/gÃ©nÃ©ration")
    else:
        print("âš¡ Performance estimÃ©e: variable selon GPU")
else:
    print("âŒ CUDA non disponible !")
    exit(1)
EOF

if [ $? -ne 0 ]; then
    echo "âŒ Erreur: GPU non dÃ©tectÃ©"
    echo "âš ï¸  RedÃ©marrez le Pod et rÃ©essayez"
    exit 1
fi

# Lancer le serveur
echo ""
echo "ðŸš€ Lancement du serveur Gaussian Splatting..."
echo "ðŸ”¥ GPU utilisÃ© Ã  100%"
echo ""

python3 main_gaussian.py
